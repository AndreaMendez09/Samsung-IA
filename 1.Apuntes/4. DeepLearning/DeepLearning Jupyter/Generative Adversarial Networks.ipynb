{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rF2x3qooyBTI"
   },
   "source": [
    "# Generative Adversarial Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2MbKJY38Puy9"
   },
   "source": [
    "[Generative Adversarial Networks](https://arxiv.org/abs/1406.2661) (GANs) son una familia de arquitecturas de redes neuronales en la cual se entrenan dos modelos simultaneos de forma competitiva.\n",
    "\n",
    "Uno de los modelos, el **generador**, se optimiza para generar muestras que se parezcan lo máximo posible a aquellas con las que se ha entrenado. Por su parte, el **discriminador** se entrena para que sea capaz de clasificar si una muestra es original o sintética, es decir, creada por el modelo **generador**.\n",
    "\n",
    "Durante el entrenamiento de la arquitectura se establece una dinámica competitiva en la que el **generador** intenta crear las muestras sintéticas lo más perfeccionadas para evitar que el **clasificador** las identifique, y viceversa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso de estudio: generando ropa con Fashion MNIST\n",
    "\n",
    "Vamos a crear una primera GAN para que genere ropa similar a la definida en el *dataset* **Fashion MNIST**. Cargamos el dataset de la forma habitual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T14:40:13.517800Z",
     "start_time": "2021-06-09T14:40:12.496945Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as K\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "(train_imgs, train_lab), (_, _) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "\n",
    "train_imgs = train_imgs.reshape(train_imgs.shape[0], 28, 28, 1).astype('float32')\n",
    "train_imgs = (train_imgs - 127.5) / 127.5 # Normalize the images in between -1 and 1\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "train_set = tf.data.Dataset.from_tensor_slices(train_imgs).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THY-sZMiQ4UV"
   },
   "source": [
    "### La red generadora\n",
    "\n",
    "Vamos a crear los modelos por separado para analizar mejor qué hace cada uno. El **modelo generador** utiliza las capas `Conv2DTranspose` para realizar *upscaling*. Partiendo de una semilla aleatoria que se conecta a una capa densa, se añaden capas `Conv2DTranspose` hasta que se alcanza la resolución objetivo. En nuestro caso, la resolución objetivo es la misma que las imágenes del conjunto de datos: $28\\times 28$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T14:40:19.891036Z",
     "start_time": "2021-06-09T14:40:19.876304Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:22.717694Z",
     "iopub.status.busy": "2021-05-19T09:23:22.717122Z",
     "iopub.status.idle": "2021-05-19T09:23:22.718741Z",
     "shell.execute_reply": "2021-05-19T09:23:22.719134Z"
    },
    "id": "6bpTcDqoLWjY"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "def generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256)\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5,5), strides=(1,1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5,5), strides=(2,2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5,5), strides=(2,2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GyWgG09LCSJl"
   },
   "source": [
    "Podemos usar la red para generar imágenes, aunque todavía no esté entrenada. Observa la entrada que se le pasa a la red (ruido aleatorio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T14:41:47.971674Z",
     "start_time": "2021-06-09T14:41:47.645597Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:22.723689Z",
     "iopub.status.busy": "2021-05-19T09:23:22.723094Z",
     "iopub.status.idle": "2021-05-19T09:23:24.744189Z",
     "shell.execute_reply": "2021-05-19T09:23:24.744575Z"
    },
    "id": "gl7jcC7TdPTG"
   },
   "outputs": [],
   "source": [
    "generator = generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_img = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_img[0,:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0IKnaCtg6WE"
   },
   "source": [
    "### La red discriminadora\n",
    "\n",
    "Con respecto al modelo discriminador, se trata de una red convolucional para clasificación binaria (**real**, **sintética**). En este caso construimos una red con dos capas convolucionales acompañadas de `Dropout`. Observa que la capa de salida consta de una única neurona, pues la salida es binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T14:44:11.723439Z",
     "start_time": "2021-06-09T14:44:11.717088Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.751481Z",
     "iopub.status.busy": "2021-05-19T09:23:24.750846Z",
     "iopub.status.idle": "2021-05-19T09:23:24.753430Z",
     "shell.execute_reply": "2021-05-19T09:23:24.752914Z"
    },
    "id": "dw2tPLmk2pEP"
   },
   "outputs": [],
   "source": [
    "def discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5,5), strides=(2,2), padding='same', input_shape=[28,28,1]))\n",
    "\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128,(5,5), strides=(2,2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QhPneagzCaQv"
   },
   "source": [
    "Podemos preguntar al modelo si la imagen generada anteriormente por el modelo **generador** es real o sintética:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T14:44:25.696130Z",
     "start_time": "2021-06-09T14:44:25.598484Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.758690Z",
     "iopub.status.busy": "2021-05-19T09:23:24.758013Z",
     "iopub.status.idle": "2021-05-19T09:23:24.813444Z",
     "shell.execute_reply": "2021-05-19T09:23:24.812868Z"
    },
    "id": "gDkA05NE6QMs"
   },
   "outputs": [],
   "source": [
    "discriminator = discriminator_model()\n",
    "\n",
    "decision_output = discriminator(generated_img)\n",
    "\n",
    "print(decision_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0FMYgY_mPfTi"
   },
   "source": [
    "### Funciones de pérdida para generador y discriminador\n",
    "\n",
    "En ambos casos estamos ante un problema de clasificación, por lo que usaremos versiones adaptadas de la entropía cruzada binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T11:43:23.249688Z",
     "start_time": "2021-06-08T11:43:23.246074Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.817858Z",
     "iopub.status.busy": "2021-05-19T09:23:24.817170Z",
     "iopub.status.idle": "2021-05-19T09:23:24.819599Z",
     "shell.execute_reply": "2021-05-19T09:23:24.819099Z"
    },
    "id": "psQfmXxYKU3X"
   },
   "outputs": [],
   "source": [
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PKY_iPSPNWoj"
   },
   "source": [
    "Para que el modelo discriminador funcione bien necesitamos que sea capaz de:\n",
    "\n",
    "- clasificar correctamente las imágenes sintéticas\n",
    "- clasificar correctamente las imágenes reales\n",
    "\n",
    "Para tener en cuenta ambas clasificaciones en la función de coste hacemos una combinación lineal de ambas por separado, básicamente una suma. Para comprobar si realiza bien sus tareas, se comparan las predicciones del discriminador en imágenes reales con un **array de unos**, y las predicciones en imágenes sintéticas con un **array de ceros**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T11:43:36.617824Z",
     "start_time": "2021-06-08T11:43:36.612222Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.824305Z",
     "iopub.status.busy": "2021-05-19T09:23:24.823587Z",
     "iopub.status.idle": "2021-05-19T09:23:24.826089Z",
     "shell.execute_reply": "2021-05-19T09:23:24.825566Z"
    },
    "id": "wkMNfBWlT-PV"
   },
   "outputs": [],
   "source": [
    "def discriminator_loss(true_output, fake_output):\n",
    "    true_loss = cross_entropy(tf.ones_like(true_output), true_output)\n",
    "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "    tot_loss = true_loss + fake_loss\n",
    "    return tot_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jd-3GCUEiKtv"
   },
   "source": [
    "Con respecto al **modelo generador**, la función de coste tiene que cuantificar cómo de bien consigue engañar al **modelo discriminador**. Dicho de otra forma, comparamos las predicciones del discriminador en imágenes sintéticas (que deberían clasificarse como falsas o cero) con un array de unos (lo que quiere decir que el discriminador las ha clasificado como reales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T11:43:47.706472Z",
     "start_time": "2021-06-08T11:43:47.703085Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.830923Z",
     "iopub.status.busy": "2021-05-19T09:23:24.830011Z",
     "iopub.status.idle": "2021-05-19T09:23:24.831986Z",
     "shell.execute_reply": "2021-05-19T09:23:24.832407Z"
    },
    "id": "90BIcCKcDMxz"
   },
   "outputs": [],
   "source": [
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos una función para pintar imágenes sintéticas creadas por el generador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T14:50:12.828171Z",
     "start_time": "2021-06-09T14:50:12.821306Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_and_plot_images(model, test_input):\n",
    "    predictions = model(test_input, training=False)\n",
    "\n",
    "    fig = plt.figure(figsize=(6,6))\n",
    "\n",
    "    for i in range(predictions.shape[0]):\n",
    "        plt.subplot(4, 4, i+1)\n",
    "        plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rw1fkAczTQYh"
   },
   "source": [
    "### Entrenamiento de la GAN\n",
    "\n",
    "Como tenemos que realizar el entrenamiento de los dos modelos de manera simultánea tenemos que usar una herramienta de *Tensorflow* que nos permite entrenar los modelos paso a paso: `GradientTape`.\n",
    "\n",
    "El proceso en cada paso de entrenamiento es el siguiente:\n",
    "\n",
    "1. Se usa el generador para crear imágenes sintéticas.\n",
    "2. Se pide al discriminador que clasifique imágenes tanto del dataset original como las sintéticas generadas en el paso anterior.\n",
    "3. Se calculan los valores de las funciones de pérdida de ambos modelos y se actualizan los pesos en función de los gradientes asociados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T15:01:52.854652Z",
     "start_time": "2021-06-09T15:01:52.741648Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.858332Z",
     "iopub.status.busy": "2021-05-19T09:23:24.857617Z",
     "iopub.status.idle": "2021-05-19T09:23:24.860313Z",
     "shell.execute_reply": "2021-05-19T09:23:24.859825Z"
    },
    "id": "3t5ibNo05jCB"
   },
   "outputs": [],
   "source": [
    "from IPython import display\n",
    "\n",
    "EPOCHS = 60\n",
    "noise_dim = 100\n",
    "num_ex_to_gen = 16\n",
    "\n",
    "seed = tf.random.normal([num_ex_to_gen,noise_dim])\n",
    "\n",
    "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "dis_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "\n",
    "# Para que la función se compile en Tensorflow\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "        generated_img = generator(noise, training=True)\n",
    "\n",
    "        true_output = discriminator(images, training=True)\n",
    "        fake_output = discriminator(generated_img, training=True)\n",
    "\n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(true_output, fake_output)\n",
    "\n",
    "    grad_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    grad_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    gen_optimizer.apply_gradients(zip(grad_generator, generator.trainable_variables))\n",
    "    dis_optimizer.apply_gradients(zip(grad_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el bucle de entrenamiento como una función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T15:01:58.692987Z",
     "start_time": "2021-06-09T15:01:58.687184Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.865908Z",
     "iopub.status.busy": "2021-05-19T09:23:24.865247Z",
     "iopub.status.idle": "2021-05-19T09:23:24.867632Z",
     "shell.execute_reply": "2021-05-19T09:23:24.867138Z"
    },
    "id": "2M7LmLtGEMQJ"
   },
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        for img_batch in dataset:\n",
    "            train_step(img_batch)\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        generate_and_plot_images(generator, seed)\n",
    "\n",
    "    # Generator after final epoch\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_plot_images(generator, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZrd4CdjR-Fp"
   },
   "source": [
    "Ahora basta con ejecutar la función de entrenamiento para que ambos modelos se optimicen simultáneamente y de manera competitiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-09T15:09:21.366179Z",
     "start_time": "2021-06-09T15:03:19.841486Z"
    },
    "execution": {
     "iopub.execute_input": "2021-05-19T09:23:24.880656Z",
     "iopub.status.busy": "2021-05-19T09:23:24.879684Z",
     "iopub.status.idle": "2021-05-19T09:26:44.147564Z",
     "shell.execute_reply": "2021-05-19T09:26:44.147008Z"
    },
    "id": "Ly3UN0SLLY2l",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:1'):\n",
    "    tf.keras.backend.clear_session()\n",
    "    train(train_set, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenada la GAN, podemos usar el modelo generador para crear imágenes sintéticas de la misma forma que hemos hecho antes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-08T11:53:50.257994Z",
     "start_time": "2021-06-08T11:53:49.685216Z"
    }
   },
   "outputs": [],
   "source": [
    "generate_and_plot_images(generator, tf.random.normal([12, 100]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Creado por **Raúl Lara Cabrera** (raul.lara@upm.es)\n",
    "\n",
    "<img src=\"https://licensebuttons.net/l/by-nc-sa/3.0/88x31.png\">"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "dcgan.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
