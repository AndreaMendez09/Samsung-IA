{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf5d9c9",
   "metadata": {},
   "source": [
    "# Planificación del proyecto <a name=\"Planificacion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a592b504",
   "metadata": {},
   "source": [
    "* [Planificación del proyecto](#Planificacion)\n",
    "* [Entenidimiento del negocio](#Entenidimiento)\n",
    "* [Comprensión de los datos](#Comprension)\n",
    "    * [Importamos librerias](#Importamos)\n",
    "    * [Cargamos el dataset](#Cargamos)\n",
    "* [Preparación de los datos](#Preparacion)\n",
    "* [Modelado Machinel Learning](#ModeladoML)\n",
    "    * [Linear Regression](#LinearR)\n",
    "        * [Ridge Regression](#Ridge)\n",
    "* [Modelado Machinel Learning](#ModeladoDL)\n",
    "* [Evaluación](#Evaluacion)\n",
    "* [Subir el modelo a Kaggle](#Subir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177656ea",
   "metadata": {},
   "source": [
    "## Entenidimiento del negocio <a name=\"Entenidimiento\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5edce474",
   "metadata": {},
   "source": [
    "En esta práctica se deben estimar los costes médidos de diferentes pacientes usando un modelo de Machine Learning, dicha practica se podrá constrastar con las compañeras en la competición de Kaggle.\n",
    "https://www.kaggle.com/c/estimacin-de-costes-mdicos-sic-ed2-2021/overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453aae4",
   "metadata": {},
   "source": [
    "## Comprensión de los datos <a name=\"Comprension\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d434f93",
   "metadata": {},
   "source": [
    "Nos han dado dos ficheros csv divididos en test y train.\n",
    "Las columnas que contienen son las siguientes:\n",
    "- id: columna identificativa para PK\n",
    "- age: edad del principal beneficiario del seguro médico.\n",
    "- sex: sexo del tomador del seguro médico.\n",
    "- bmi: indice de masa corporal.\n",
    "- children: número de hijos cubiertos por el seguro médico / número de descendientes.\n",
    "- smoker: fumador.\n",
    "- region: área residencial del beneficiario del seguro médico.\n",
    "- charges: costes médicos cargados a la aseguradora. Dicha columna no la tiene test.\n",
    "\n",
    "A continuación cargaremos los datos para su correspondiente procesamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dba195",
   "metadata": {},
   "source": [
    "### Importamos librerias <a name=\"Importamos\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69f1ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import datasets,decomposition\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, BayesianRidge\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.optimizers import adam_v2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7301e4fd",
   "metadata": {},
   "source": [
    "### Cargamos el dataset <a name=\"Cargamos\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980fa6bb",
   "metadata": {},
   "source": [
    "En este caso tenemos el dataset dividido en dos ficheros, la parte de entrenamiento en _train.csv_ y la parte de validación en _test.csv_, por lo tanto creamos dos variables para ellos y hacemos drop de la PK ya que no es necesaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6dfe1436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1229</td>\n",
       "      <td>58</td>\n",
       "      <td>male</td>\n",
       "      <td>30.305</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>11938.25595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073</td>\n",
       "      <td>54</td>\n",
       "      <td>female</td>\n",
       "      <td>28.880</td>\n",
       "      <td>2</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>12096.65120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>64</td>\n",
       "      <td>female</td>\n",
       "      <td>39.700</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>southwest</td>\n",
       "      <td>14319.03100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>27</td>\n",
       "      <td>female</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>3558.62025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342</td>\n",
       "      <td>60</td>\n",
       "      <td>female</td>\n",
       "      <td>27.550</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northeast</td>\n",
       "      <td>13217.09450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  age     sex     bmi  children smoker     region      charges\n",
       "0  1229   58    male  30.305         0     no  northeast  11938.25595\n",
       "1  1073   54  female  28.880         2     no  northeast  12096.65120\n",
       "2   768   64  female  39.700         0     no  southwest  14319.03100\n",
       "3   606   27  female  25.175         0     no  northeast   3558.62025\n",
       "4   342   60  female  27.550         0     no  northeast  13217.09450"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Parte para el entrenamiento\n",
    "dataset_train = pd.read_csv('train.csv')\n",
    "#dataset_train = dataset_train.drop('id', 1) # Para el entrenamiento no usamos los ids\n",
    "\n",
    "#Parte para la validacion\n",
    "dataset_test = pd.read_csv('test.csv')\n",
    "#dataset_test = dataset_test.drop('id', 1) # Para la validacion no usamos los ids\n",
    "\n",
    "dataset_train.head()\n",
    "#dataset_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774cfaf4",
   "metadata": {},
   "source": [
    "Podemos comprobar que tenemos tres variables que no son númericas que son ``sex``, ``smoker`` y ``region``. De las cuales ``sex`` y ``smoker`` son variables binarias, a continuación comprobamos los datos que puede tener ``region`` para saber como prepararla en el siguiente paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a5cea26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "southeast    251\n",
       "northeast    235\n",
       "northwest    231\n",
       "southwest    219\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945ccc7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "male      481\n",
       "female    455\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c18dd431",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     733\n",
       "yes    203\n",
       "Name: smoker, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762c004a",
   "metadata": {},
   "source": [
    "Comprobamos que en este caso, region tiene cuatro posibilidades, será tratada en la siguiente fase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7382b10",
   "metadata": {},
   "source": [
    "## Preparación de los datos <a name=\"Preparacion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "478e8e58",
   "metadata": {},
   "source": [
    "Para tener todas nuestras variables de forma numerica, pasaremos las mencionadas anteriormente por un **LabelEncoder**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9548f2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1229</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>30.305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11938.25595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12096.65120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>39.700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>14319.03100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3558.62025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>27.550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13217.09450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  age  sex     bmi  children  smoker  region      charges\n",
       "0  1229   58    1  30.305         0       0       0  11938.25595\n",
       "1  1073   54    0  28.880         2       0       0  12096.65120\n",
       "2   768   64    0  39.700         0       0       3  14319.03100\n",
       "3   606   27    0  25.175         0       0       0   3558.62025\n",
       "4   342   60    0  27.550         0       0       0  13217.09450"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "# Para la parte de entrenamiento\n",
    "dataset_train['sex'] = le.fit_transform(dataset_train['sex'])\n",
    "dataset_train['smoker'] = le.fit_transform(dataset_train['smoker'])\n",
    "dataset_train['region'] = le.fit_transform(dataset_train['region'])\n",
    "\n",
    "# Para la parte de validación\n",
    "dataset_test['sex'] = le.fit_transform(dataset_test['sex'])\n",
    "dataset_test['smoker'] = le.fit_transform(dataset_test['smoker'])\n",
    "dataset_test['region'] = le.fit_transform(dataset_test['region'])\n",
    "\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0215f1",
   "metadata": {},
   "source": [
    "Como vemos a continuación, ha dejado de tener la cadena de texto y ha pasado a tener un número categorico. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c15748e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    251\n",
       "0    235\n",
       "1    231\n",
       "3    219\n",
       "Name: region, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "405bcad7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    481\n",
       "0    455\n",
       "Name: sex, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0bb0a3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    733\n",
       "1    203\n",
       "Name: smoker, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train['smoker'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8132e5",
   "metadata": {},
   "source": [
    "A continuación realizaremos un **MinMaxScaler** para normalizar las variables y que ninguna categoría de una columna tenga más peso que otra, para así entrenar a nuestro modelo correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f32042e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>30.305</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>28.880</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>39.700</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>25.175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>27.550</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>32.450</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>39.160</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>55</td>\n",
       "      <td>0</td>\n",
       "      <td>29.830</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>33.300</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>42.130</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex     bmi  children  smoker  region\n",
       "0     58    1  30.305         0       0       0\n",
       "1     54    0  28.880         2       0       0\n",
       "2     64    0  39.700         0       0       3\n",
       "3     27    0  25.175         0       0       0\n",
       "4     60    0  27.550         0       0       0\n",
       "..   ...  ...     ...       ...     ...     ...\n",
       "931   60    0  32.450         0       1       2\n",
       "932   62    0  39.160         0       0       2\n",
       "933   55    0  29.830         0       0       0\n",
       "934   20    0  33.300         0       0       3\n",
       "935   57    1  42.130         1       1       2\n",
       "\n",
       "[936 rows x 6 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train.iloc[:,1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73a562a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parte para el entrenamiento\n",
    "sc_train = MinMaxScaler()\n",
    "sc_train.fit(dataset_train.iloc[:,1:-1]) # Se ajusta el reescalador, y omitimos la columna de id, para que no la normalice\n",
    "dataset_train[['age','sex','bmi','children','smoker','region']] = sc_train.transform(dataset_train[['age','sex','bmi','children','smoker','region']])\n",
    "\n",
    "#Parte para validacion\n",
    "sc_test = MinMaxScaler()\n",
    "sc_test.fit(dataset_test.iloc[:,1:]) # Se ajusta el reescalador\n",
    "dataset_test[['age','sex','bmi','children','smoker','region']] = sc_test.transform(dataset_test[['age','sex','bmi','children','smoker','region']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4d3d0d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1229</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11938.25595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1073</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337341</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12096.65120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>14319.03100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>606</td>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3558.62025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>342</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13217.09450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>845</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>45008.95550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>928</td>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>13470.80440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>1091</td>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11286.53870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>1268</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1880.48700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>530</td>\n",
       "      <td>0.847826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707815</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>48675.51770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id       age  sex       bmi  children  smoker    region      charges\n",
       "0    1229  0.869565  1.0  0.377184       0.0     0.0  0.000000  11938.25595\n",
       "1    1073  0.782609  0.0  0.337341       0.4     0.0  0.000000  12096.65120\n",
       "2     768  1.000000  0.0  0.639871       0.0     0.0  1.000000  14319.03100\n",
       "3     606  0.195652  0.0  0.233748       0.0     0.0  0.000000   3558.62025\n",
       "4     342  0.913043  0.0  0.300154       0.0     0.0  0.000000  13217.09450\n",
       "..    ...       ...  ...       ...       ...     ...       ...          ...\n",
       "931   845  0.913043  0.0  0.437159       0.0     1.0  0.666667  45008.95550\n",
       "932   928  0.956522  0.0  0.624773       0.0     0.0  0.666667  13470.80440\n",
       "933  1091  0.804348  0.0  0.363903       0.0     0.0  0.000000  11286.53870\n",
       "934  1268  0.043478  0.0  0.460925       0.0     0.0  1.000000   1880.48700\n",
       "935   530  0.847826  1.0  0.707815       0.2     1.0  0.666667  48675.51770\n",
       "\n",
       "[936 rows x 8 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "318730d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Otra forma de realizar el MinMaxScaler, esta variable no se utilizara en este ejercicio\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(dataset_train.iloc[:,1:]), columns=['age','sex','bmi','children','smoker','region','charges'], index=dataset_train.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0621309e",
   "metadata": {},
   "source": [
    "Teniendo el dataset cargado y las variables normalizadas, ahora tendremos que separar la columna a predecir, que en este caso es ``charges`` y dividir nuestro dataset en las variables correspondientes. Tales como:\n",
    "- X_train: Será nuestra fuente de datos para el entrenamiento.\n",
    "- Y_train: Será nuestra fuente de datos de entrenamiento para la variable a predecir.\n",
    "- X_test: Será nuestra fuente de datos de validación, la cual no le ofreceremos la variable a predecir.\n",
    "- Y_test: Será nuestra fuente de datos de validación, sirve para obtener el rendimiento de nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55b597f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MinMaxScaler nos devuelve un numpy array, lo pasamos a pandas DataFrame para poder trabajar mejor\n",
    "dataset_train = pd.DataFrame(dataset_train)\n",
    "dataset_test = pd.DataFrame(dataset_test)\n",
    "\n",
    "# Se separa la columna a predecir\n",
    "X_train = dataset_train.iloc[:,1:-1] #Ignoramos la columna de Id \n",
    "Y_train = dataset_train.iloc[:,-1]\n",
    "X_test = dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b38cd06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11938.25595\n",
       "1      12096.65120\n",
       "2      14319.03100\n",
       "3       3558.62025\n",
       "4      13217.09450\n",
       "          ...     \n",
       "931    45008.95550\n",
       "932    13470.80440\n",
       "933    11286.53870\n",
       "934     1880.48700\n",
       "935    48675.51770\n",
       "Name: charges, Length: 936, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a883bcff",
   "metadata": {},
   "source": [
    "## Modelado Machinel Learning <a name=\"ModeladoML\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af5bb282",
   "metadata": {},
   "source": [
    "Tenemos ya los datos correctos y normalizados, ahora toca elegir el tipo de modelo que vamos a desarrollar y la estructura que más se adecue, probaremos varias para constrastar datos.\n",
    "\n",
    "En este caso, al tener claramente una variable de salida no categorica, por lo tanto descaramos _Clasificacion_ , como tenemos variable de salida, descartamos _Clustering_, nos quedaría la opción más sensata que es **Regresion**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff55b700",
   "metadata": {},
   "source": [
    "### Linear Regression <a name=\"LinearR\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a9757c",
   "metadata": {},
   "source": [
    "Realizaremos este primer modelo, asumiendo que existe una correlación lineal entre los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85e4a916",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con los datos de entrenamiento:  0.7496636971119938\n"
     ]
    }
   ],
   "source": [
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "print(\"Con los datos de entrenamiento: \", reg.score(X_train, Y_train)) #Normalmente lo comprobaria con el score de los\n",
    "#datos de test, para comprobar el overfitting pero acutalmente no dispongo de Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28bf9ac5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2145.1746072827045"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7478961f",
   "metadata": {},
   "source": [
    "Como norma general:\n",
    "\n",
    "- Los valores positivos en estos coeficientes significan una correlación directa entre los valores de las características que representan los coeficientes y el coste medico a la aseguradora, mientras que los valores negativos representan una correlación inversa.\n",
    "- La magnitud de los coeficientes miden el grado de aportación, positiva o negativa, de una determinada característica.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ccd0b940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12435.62723763,    26.01948286, 12478.8115806 ,  1517.91753992,\n",
       "       23754.01188298,  -624.48267979])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5be9cbff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12435.627238</td>\n",
       "      <td>26.019483</td>\n",
       "      <td>12478.811581</td>\n",
       "      <td>1517.91754</td>\n",
       "      <td>23754.011883</td>\n",
       "      <td>-624.48268</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            age        sex           bmi    children        smoker     region\n",
       "0  12435.627238  26.019483  12478.811581  1517.91754  23754.011883 -624.48268"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=np.expand_dims(reg.coef_, axis=0), columns=['age','sex','bmi','children','smoker','region'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adaabcc4",
   "metadata": {},
   "source": [
    "Como vemos los datos de **intercept** y los **coeficientes** son bastante exagerados, esto declara un overfitting que es el principal problema de este modelo, se podría solucionar con _Ridge Regression_ hagamos una prueba con el antes de pasar al siguiente modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75927988",
   "metadata": {},
   "source": [
    "La subida a Kaggle ha dado un **score: 0.72993**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0b51225",
   "metadata": {},
   "source": [
    "#### Ridge Regression <a name=\"Ridge\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f140d1",
   "metadata": {},
   "source": [
    "##### Prueba 1 de encontrar el mejor alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8437b5",
   "metadata": {},
   "source": [
    "Para mejorar el modelo anterior y evitar que los outlayers afecten a nuestro resultado, vamos a quitarlos con **StandardScaler**.\n",
    "\n",
    "También aplicaremos **PCA** su objetivo es encontrar las columnas principales y reducir la dimensionalidad del conjunto de datos ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5da32832",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_slc = StandardScaler()\n",
    "pca = decomposition.PCA() #Decomposition reduce el numero de columnas, es uno de los PCA que he entendido, \n",
    "#Es probable que exista un PCA mejor para este dataset\n",
    "ridge = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "655f47c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline(steps=[(\"std_slc\", std_slc),\n",
    "                       (\"pca\", pca),\n",
    "                       (\"ridge\", ridge)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8d2c839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_components = list(range(1,X_train.shape[1]+1,1))\n",
    "n_components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362bf9b0",
   "metadata": {},
   "source": [
    "Como en casi todos los modelos, existen distintas arquitecturas para el mismo modelo, cada una con sus ventajas y desventajas, añadiremos todas para que nos ofrezca la que mejor resultado de. \n",
    "\n",
    "Puedes mirar el funcionamiento de cada una aquí https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html?highlight=ridge#sklearn.linear_model.Ridge\n",
    "\n",
    "Ha raíz de esto, he decidido quitar _lbfgs_ ya que aunque los datos estan normalizados, no están normalizados por el método, por lo tanto, lo he desechado para las pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "640166ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos una lista con todos los parametros de Ridge Regression\n",
    "solver = [\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f2158288",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = dict(pca__n_components=n_components,\n",
    "                  ridge__normalize=[True, False],\n",
    "                  ridge__alpha=np.arange(1e-3,5,0.05),\n",
    "                  ridge__solver=solver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ea51bb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('std_slc', StandardScaler()),\n",
       "                                       ('pca', PCA()), ('ridge', Ridge())]),\n",
       "             param_grid={'pca__n_components': [1, 2, 3, 4, 5, 6],\n",
       "                         'ridge__alpha': array([1.000e-03, 5.100e-02, 1.010e-01, 1.510e-01, 2.010e-01, 2.510e-01,\n",
       "       3.010e-01, 3.510e-01, 4.010e-01, 4.510e-01, 5.010e-01, 5.510e-01,\n",
       "       6.010e-01, 6.510e-01, 7.010e-01, 7.510e-01, 8.010e-01, 8.510e-01,...\n",
       "       3.601e+00, 3.651e+00, 3.701e+00, 3.751e+00, 3.801e+00, 3.851e+00,\n",
       "       3.901e+00, 3.951e+00, 4.001e+00, 4.051e+00, 4.101e+00, 4.151e+00,\n",
       "       4.201e+00, 4.251e+00, 4.301e+00, 4.351e+00, 4.401e+00, 4.451e+00,\n",
       "       4.501e+00, 4.551e+00, 4.601e+00, 4.651e+00, 4.701e+00, 4.751e+00,\n",
       "       4.801e+00, 4.851e+00, 4.901e+00, 4.951e+00]),\n",
       "                         'ridge__normalize': [True, False],\n",
       "                         'ridge__solver': ['auto', 'svd', 'cholesky', 'lsqr',\n",
       "                                           'sparse_cg', 'sag', 'saga']})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_GS = GridSearchCV(pipe, parameters)\n",
    "clf_GS.fit(X_train, Y_train) #Pasamos las variables de train, ya que nuestro test no tenemos disponible la Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "101b865c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Number Of Components: 6\n",
      "\n",
      "Ridge(alpha=3.851, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Number Of Components:\", clf_GS.best_estimator_.get_params()[\"pca__n_components\"])\n",
    "print(); print(clf_GS.best_estimator_.get_params()[\"ridge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "917fc5c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Con los datos de entrenamiento:  0.7486545086160235\n"
     ]
    }
   ],
   "source": [
    "ridge = Ridge(alpha= 3.851, solver='saga').fit(X_train, Y_train)\n",
    "print(\"Con los datos de entrenamiento: \", ridge.score(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4c2431",
   "metadata": {},
   "source": [
    "##### Prueba 2 de encontrar el mejor alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8df216b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.901}\n",
      "-0.7403519346584229\n"
     ]
    }
   ],
   "source": [
    "ridge_2 = Ridge() #Creamos nuestro modelo\n",
    "\n",
    "rango_alpha = {'alpha':np.arange(1e-3,5,0.05)}#Establecemos el rango con el que probar para nuestro alpha\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge_2, rango_alpha, scoring=\"r2\", cv = 10) #Creamos el GridSearch para que pruebe\n",
    "\n",
    "ridge_regressor.fit(X_train,Y_train)\n",
    "\n",
    "#Obtenemos los datos que son mejores\n",
    "ridge_best_params_ = ridge_regressor.best_params_\n",
    "ridge_best_score_ = -ridge_regressor.best_score_\n",
    "print(ridge_best_params_); print(ridge_best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0919e7ac",
   "metadata": {},
   "source": [
    "#### Conclusion de Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c64ab",
   "metadata": {},
   "source": [
    "Aunque normalmente suele ser una buena opción usar algun derivado de Linear Regression mejor que el puro,aun usando dos técnicas para obtener la mejor combinación de hiperparametros, no he conseguido mejorar el score de la versión pura de LinearRegression.\n",
    "\n",
    "    Aún así, dejo documentado las pruebas, por si fuese un error de ejecución o código en este caso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3827e8",
   "metadata": {},
   "source": [
    "### Polynomial signs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cd45ba",
   "metadata": {},
   "source": [
    "Debido a que mis pruebas con Ridge regression no han salido como esperaba, he investigado formas distintas de regresiones, y he encontrado que la polinomica suele dar buenos resultados, por lo tanto voy a probar por primera vez este modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1dbd94",
   "metadata": {},
   "source": [
    "#### Prueba 1 modelo polinómico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8269ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2) #Elevamos al cuadrado\n",
    "x_poly = poly.fit_transform(X_train)\n",
    "\n",
    "X_train_poly,X_test_poly,Y_train_poly,Y_test_poly = train_test_split(x_poly,Y_train)\n",
    "\n",
    "plreg = LinearRegression().fit(X_train_poly,Y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b5e3f016",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8349931515155394\n"
     ]
    }
   ],
   "source": [
    "print(plreg.score(X_test_poly,Y_test_poly))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07961a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8440412274954883\n"
     ]
    }
   ],
   "source": [
    "print(plreg.score(X_train_poly,Y_train_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ea470",
   "metadata": {},
   "source": [
    "Aunque este modelo parece funcionar correctamente, tengo problemas al intentar pasarlo a Kaggle, que lo he intentado hacer de la siguiente manera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "ff4be01b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.56521739 1.         ... 0.         0.         0.        ]\n",
      " [1.         0.45652174 0.         ... 0.         0.         1.        ]\n",
      " [1.         0.36956522 0.         ... 0.         0.         0.11111111]\n",
      " ...\n",
      " [1.         0.36956522 1.         ... 0.         0.         0.44444444]\n",
      " [1.         0.63043478 1.         ... 1.         1.         1.        ]\n",
      " [1.         0.39130435 0.         ... 0.         0.         0.44444444]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_quad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "379720ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test_pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4746d965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-b4dfea283304>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Creamos el dataframe para mandarlo despues al CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msubmission\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mX_test_quad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'charges'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mY_test_pred\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m# Pasamos el dataframe a CSV\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'submission.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mmgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[1;34m(data, index, columns, dtype)\u001b[0m\n\u001b[0;32m    285\u001b[0m             \u001b[0marr\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         ]\n\u001b[1;32m--> 287\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    288\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m         \u001b[1;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m         \u001b[0marrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_homogenize\u001b[1;34m(data, index, dtype)\u001b[0m\n\u001b[0;32m    353\u001b[0m                     \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                 \u001b[0mval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 355\u001b[1;33m             val = sanitize_array(\n\u001b[0m\u001b[0;32m    356\u001b[0m                 \u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraise_cast_failure\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m             )\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\pandas\\core\\construction.py\u001b[0m in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0msubarr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data must be 1-dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m             \u001b[0msubarr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_tuplesafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Data must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "# Creamos el dataframe para mandarlo despues al CSV\n",
    "submission = pd.DataFrame({'id': X_test_quad, 'charges': Y_test_pred})\n",
    "# Pasamos el dataframe a CSV\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304fc0e9",
   "metadata": {},
   "source": [
    "Mi problema aquí es tanto con la dimensionalidad de X_test_quad, ya que ha dejado de ser un dataframe y ha pasado a ser un numpy array, por lo tanto también hemos perdido el valor de ID (ya que de todas maneras x_poly bebe de X_train que le quitamos el ID previamente). \n",
    "\n",
    "Vamos a intentarlo de otra manera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2dc4fe",
   "metadata": {},
   "source": [
    "#### Prueba 2 modelo polinómico "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c2bc9e",
   "metadata": {},
   "source": [
    "Siguiendo el consejo de Raúl, que comenta lo siguiente:\n",
    "   \n",
    "    Tienes que aplicar la misma transformación de PolynomialFeatures sobre X_test para que genere las variables al cuadrado poly_test = poly.fit_transform(X_test). Una vez tienes poly_test ya puedes hacer el predict sobre él y crear un nuevo DataFrame con la columna de predicciones y la columna id, igual que hacías con el X_test sin ser polinómico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e4970bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(degree = 2) #Elevamos al cuadrado\n",
    "poly_test = poly.fit_transform(X_test.iloc[:,1:]) #Quitamos el id antes de pasarlo\n",
    "x_poly = poly.fit_transform(X_train)\n",
    "\n",
    "X_train_poly,X_test_poly,Y_train_poly,Y_test_poly = train_test_split(x_poly,Y_train)\n",
    "\n",
    "plreg = LinearRegression().fit(X_train_poly,Y_train_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ecbf1b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8596156374889231\n"
     ]
    }
   ],
   "source": [
    "print(plreg.score(X_test_poly,Y_test_poly)) #Comprobamos el resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2440f5d7",
   "metadata": {},
   "source": [
    "Y ahora pondremos poly_test como el predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "328827cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos el modelo que queramos mandar a Kaggle\n",
    "predicted_charges = plreg.predict(poly_test)\n",
    "# Creamos el dataframe para mandarlo despues al CSV\n",
    "submission = pd.DataFrame({'id': X_test.iloc[:,0:1].to_numpy().flatten(), 'charges': predicted_charges})\n",
    "# Pasamos el dataframe a CSV\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4e8409",
   "metadata": {},
   "source": [
    "Bien, de esta manera si que hemos conseguido subirlo correctamente a Kaggle y el resultado es mejor que las regresiones lineales realizadas anteriormente, he conseguido un **score de 0.82042**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbaf1ce",
   "metadata": {},
   "source": [
    "## Modelado Deep Learning <a name=\"ModeladoDL\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f1a0fe",
   "metadata": {},
   "source": [
    "Elegiremos primero el tipo de DL:\n",
    " - **Red Neuronal Convolucional (CNN)**, este tipo de modelo esta diseñado exclusivamente para el reconocimiento de imagenes, por lo tanto lo descarto.\n",
    " - **Red Neuronal Recurrente (RNN)**, se utiliza principalmente para modelos que tengan como datos el lenguaje natural. Este tampoco es nuestro caso, por lo tanto lo descarto.\n",
    " - **AutoEncoder**, \n",
    " - **Red Generativa Antagónica (GAN)**, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "62936100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "22/22 [==============================] - 1s 9ms/step - loss: 14109.1582 - mae: 14109.1582 - val_loss: 11849.4502 - val_mae: 11849.4502\n",
      "Epoch 2/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14108.8887 - mae: 14108.8887 - val_loss: 11849.1963 - val_mae: 11849.1963\n",
      "Epoch 3/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14108.6240 - mae: 14108.6240 - val_loss: 11848.9395 - val_mae: 11848.9395\n",
      "Epoch 4/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14108.3516 - mae: 14108.3516 - val_loss: 11848.6729 - val_mae: 11848.6729\n",
      "Epoch 5/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14108.0654 - mae: 14108.0654 - val_loss: 11848.3867 - val_mae: 11848.3867\n",
      "Epoch 6/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14107.7520 - mae: 14107.7520 - val_loss: 11848.0703 - val_mae: 11848.0703\n",
      "Epoch 7/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14107.4062 - mae: 14107.4062 - val_loss: 11847.7178 - val_mae: 11847.7178\n",
      "Epoch 8/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14107.0215 - mae: 14107.0215 - val_loss: 11847.3193 - val_mae: 11847.3193\n",
      "Epoch 9/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14106.5840 - mae: 14106.5840 - val_loss: 11846.8672 - val_mae: 11846.8672\n",
      "Epoch 10/40\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 14106.0869 - mae: 14106.0869 - val_loss: 11846.3496 - val_mae: 11846.3496\n",
      "Epoch 11/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14105.5146 - mae: 14105.5146 - val_loss: 11845.7627 - val_mae: 11845.7627\n",
      "Epoch 12/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14104.8691 - mae: 14104.8691 - val_loss: 11845.0986 - val_mae: 11845.0986\n",
      "Epoch 13/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14104.1455 - mae: 14104.1455 - val_loss: 11844.3506 - val_mae: 11844.3506\n",
      "Epoch 14/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14103.3350 - mae: 14103.3350 - val_loss: 11843.5195 - val_mae: 11843.5195\n",
      "Epoch 15/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14102.4326 - mae: 14102.4326 - val_loss: 11842.6055 - val_mae: 11842.6055\n",
      "Epoch 16/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14101.4463 - mae: 14101.4463 - val_loss: 11841.6025 - val_mae: 11841.6025\n",
      "Epoch 17/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14100.3672 - mae: 14100.3672 - val_loss: 11840.5205 - val_mae: 11840.5205\n",
      "Epoch 18/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14099.2051 - mae: 14099.2051 - val_loss: 11839.3457 - val_mae: 11839.3457\n",
      "Epoch 19/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14097.9502 - mae: 14097.9502 - val_loss: 11838.0811 - val_mae: 11838.0811\n",
      "Epoch 20/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14096.6035 - mae: 14096.6035 - val_loss: 11836.7344 - val_mae: 11836.7344\n",
      "Epoch 21/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14095.1680 - mae: 14095.1680 - val_loss: 11835.2959 - val_mae: 11835.2959\n",
      "Epoch 22/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14093.6436 - mae: 14093.6436 - val_loss: 11833.7832 - val_mae: 11833.7832\n",
      "Epoch 23/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14092.0332 - mae: 14092.0332 - val_loss: 11832.1748 - val_mae: 11832.1748\n",
      "Epoch 24/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14090.3291 - mae: 14090.3291 - val_loss: 11830.4814 - val_mae: 11830.4814\n",
      "Epoch 25/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14088.5410 - mae: 14088.5410 - val_loss: 11828.7021 - val_mae: 11828.7021\n",
      "Epoch 26/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14086.6611 - mae: 14086.6611 - val_loss: 11826.8457 - val_mae: 11826.8457\n",
      "Epoch 27/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14084.6982 - mae: 14084.6982 - val_loss: 11824.9023 - val_mae: 11824.9023\n",
      "Epoch 28/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14082.6514 - mae: 14082.6514 - val_loss: 11822.8740 - val_mae: 11822.8740\n",
      "Epoch 29/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14080.5146 - mae: 14080.5146 - val_loss: 11820.7686 - val_mae: 11820.7686\n",
      "Epoch 30/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14078.2959 - mae: 14078.2959 - val_loss: 11818.5811 - val_mae: 11818.5811\n",
      "Epoch 31/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14075.9912 - mae: 14075.9912 - val_loss: 11816.3145 - val_mae: 11816.3145\n",
      "Epoch 32/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14073.6123 - mae: 14073.6123 - val_loss: 11813.9590 - val_mae: 11813.9590\n",
      "Epoch 33/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14071.1436 - mae: 14071.1436 - val_loss: 11811.5273 - val_mae: 11811.5273\n",
      "Epoch 34/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14068.5996 - mae: 14068.5996 - val_loss: 11809.0215 - val_mae: 11809.0215\n",
      "Epoch 35/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14065.9668 - mae: 14065.9668 - val_loss: 11806.4551 - val_mae: 11806.4551\n",
      "Epoch 36/40\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 14063.2773 - mae: 14063.2773 - val_loss: 11803.7910 - val_mae: 11803.7910\n",
      "Epoch 37/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14060.4883 - mae: 14060.4883 - val_loss: 11801.0693 - val_mae: 11801.0693\n",
      "Epoch 38/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14057.6455 - mae: 14057.6455 - val_loss: 11798.2588 - val_mae: 11798.2588\n",
      "Epoch 39/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14054.7051 - mae: 14054.7051 - val_loss: 11795.3945 - val_mae: 11795.3945\n",
      "Epoch 40/40\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 14051.7051 - mae: 14051.7051 - val_loss: 11792.4521 - val_mae: 11792.4521\n"
     ]
    }
   ],
   "source": [
    "insurance = Sequential([\n",
    "      Dense(10),\n",
    "      Dense(1),\n",
    "])\n",
    "\n",
    "insurance.compile(loss='mae',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mae'])\n",
    "\n",
    "X_train_rnn,X_test_rnn,Y_train_rnn,Y_test_rnn = train_test_split(X_train,Y_train)\n",
    "\n",
    "history = insurance.fit(X_train_rnn,\n",
    "                        Y_train_rnn, validation_data=(X_test_rnn, Y_test_rnn), #No se muy bien que poner aqui\n",
    "                        epochs=40, verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e09b103",
   "metadata": {},
   "source": [
    "## Evaluación <a name=\"Evaluacion\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df22d69",
   "metadata": {},
   "source": [
    "## Subir el modelo a Kaggle <a name=\"Subir\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2d325c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kaggle\n",
      "  Downloading kaggle-1.5.12.tar.gz (58 kB)\n",
      "Requirement already satisfied: six>=1.10 in d:\\programas\\anaconda\\lib\\site-packages (from kaggle) (1.15.0)\n",
      "Requirement already satisfied: certifi in d:\\programas\\anaconda\\lib\\site-packages (from kaggle) (2020.12.5)\n",
      "Requirement already satisfied: python-dateutil in d:\\programas\\anaconda\\lib\\site-packages (from kaggle) (2.8.1)\n",
      "Requirement already satisfied: requests in d:\\programas\\anaconda\\lib\\site-packages (from kaggle) (2.25.1)\n",
      "Requirement already satisfied: tqdm in d:\\programas\\anaconda\\lib\\site-packages (from kaggle) (4.59.0)\n",
      "Collecting python-slugify\n",
      "  Downloading python_slugify-5.0.2-py2.py3-none-any.whl (6.7 kB)\n",
      "Requirement already satisfied: urllib3 in d:\\programas\\anaconda\\lib\\site-packages (from kaggle) (1.26.4)\n",
      "Collecting text-unidecode>=1.3\n",
      "  Downloading text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: idna<3,>=2.5 in d:\\programas\\anaconda\\lib\\site-packages (from requests->kaggle) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in d:\\programas\\anaconda\\lib\\site-packages (from requests->kaggle) (4.0.0)\n",
      "Building wheels for collected packages: kaggle\n",
      "  Building wheel for kaggle (setup.py): started\n",
      "  Building wheel for kaggle (setup.py): finished with status 'done'\n",
      "  Created wheel for kaggle: filename=kaggle-1.5.12-py3-none-any.whl size=73053 sha256=c071b97fd94c4fdd516b9f82f7eff1e503af7465f2da227b2787dd36db4c8be5\n",
      "  Stored in directory: c:\\users\\amendezsa\\appdata\\local\\pip\\cache\\wheels\\29\\da\\11\\144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106\n",
      "Successfully built kaggle\n",
      "Installing collected packages: text-unidecode, python-slugify, kaggle\n",
      "Successfully installed kaggle-1.5.12 python-slugify-5.0.2 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3e9aaabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.869565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.377184</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.337341</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.639871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.195652</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233748</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.300154</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>931</th>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>932</th>\n",
       "      <td>0.956522</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.624773</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0.804348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.460925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>0.847826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.707815</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>936 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age  sex       bmi  children  smoker    region\n",
       "0    0.869565  1.0  0.377184       0.0     0.0  0.000000\n",
       "1    0.782609  0.0  0.337341       0.4     0.0  0.000000\n",
       "2    1.000000  0.0  0.639871       0.0     0.0  1.000000\n",
       "3    0.195652  0.0  0.233748       0.0     0.0  0.000000\n",
       "4    0.913043  0.0  0.300154       0.0     0.0  0.000000\n",
       "..        ...  ...       ...       ...     ...       ...\n",
       "931  0.913043  0.0  0.437159       0.0     1.0  0.666667\n",
       "932  0.956522  0.0  0.624773       0.0     0.0  0.666667\n",
       "933  0.804348  0.0  0.363903       0.0     0.0  0.000000\n",
       "934  0.043478  0.0  0.460925       0.0     0.0  1.000000\n",
       "935  0.847826  1.0  0.707815       0.2     1.0  0.666667\n",
       "\n",
       "[936 rows x 6 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "800a58dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "402"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test.iloc[:,0:1].to_numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d715854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos el modelo que queramos mandar a Kaggle\n",
    "predicted_charges = reg.predict(X_test.iloc[:,1:])\n",
    "# Creamos el dataframe para mandarlo despues al CSV\n",
    "submission = pd.DataFrame({'id': X_test.iloc[:,0:1].to_numpy().flatten(), 'charges': predicted_charges})\n",
    "# Pasamos el dataframe a CSV\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159ea10a",
   "metadata": {},
   "source": [
    "Descomentar la siguiente línea para hacer la subida a kaggle a traves de su api, esto es posible porque tengo el token de mi perfil en mi ruta de la variable de entorno, por si quereis obtener más información visitar este link.\n",
    "https://github.com/Kaggle/kaggle-api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f74d17c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully submitted to Estimación de costes médicos (SIC - Ed.2 - 2021)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/9.24k [00:00<?, ?B/s]\n",
      "100%|##########| 9.24k/9.24k [00:02<00:00, 4.14kB/s]\n"
     ]
    }
   ],
   "source": [
    "#!kaggle competitions submit -c estimacin-de-costes-mdicos-sic-ed2-2021 -f submission.csv -m \"Modelo ML con Regresion Polinomica prueba 2.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ceb8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
