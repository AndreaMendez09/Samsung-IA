{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba #0501"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Regresión Logísitica y algoritmo de Gradiente Descendente\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Responda las siguientes preguntas proporcionando código Python:\n",
    "#### Objetivos:\n",
    "- Codifique una clase de regresión logística utilizando solo la biblioteca NumPy.\n",
    "- Implementar en Python la función Sigmoid.\n",
    "- Implementar en Python el Gradiente de la probabilidad logarítmica.\n",
    "- Implementar en Python el algoritmo de gradiente descendente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings(action='ignore')                  # Desactiva las advertencias."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Leer los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "data = load_breast_cancer()\n",
    "# Variables explicativas\n",
    "X = data['data']\n",
    "# Volver a etiquetar para que 0 = 'benign' y 1 = malignant.\n",
    "Y = 1 - data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir el conjunto de datos en entrenamiento y prueba.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4, random_state=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1). Defina las funciones 'sigmoide' y 'gradiente' para producir el resultado que se muestra a continuación:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Función sigmoide:\n",
    "\n",
    "$$\n",
    "logit(x) = \\frac{1}{1+ e^{-x}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descenso de gradiente:\n",
    "\n",
    "$$\n",
    "w_j \\leftarrow w_j - \\eta \\left(\\frac{1}{n} \\sum_{i=1}^{n} x_{i,j} ( logit(wx_i+b)-y_i) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x)) \n",
    "    \n",
    "def gradient(X, Y, beta):\n",
    "    x_por_betas = np.dot(X, beta)\n",
    "    pred = sigmoid(x_por_betas)\n",
    "    error_obt = pred - Y\n",
    "    return (1/Y.size)*np.dot(X.T, error_obt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2). Defina la clase 'LogisticRegression' para producir el resultado que se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression:\n",
    "    def __init__(self, learn_rate):\n",
    "        # learn_rate: Hiperparámetro para el regresor Stochastic Gradient Descent (SGDRegressor)\n",
    "        self.learning_rate = learn_rate\n",
    "        self.beta = np.array([])\n",
    "        self.beta2 = np.array([])\n",
    "        \n",
    "    def train(self, input_X, input_Y, n_epochs):\n",
    "        # inicializar beta\n",
    "        self.beta = np.zeros(input_X[0,:].size+1)\n",
    "        self.beta2 = np.zeros(input_X[0,:].size+1)\n",
    "        # se incluye un 1 a los datos para que la primera columna se multiplique por beta0\n",
    "        col_1s = np.ones((input_X.shape[0],1))\n",
    "        X_train_con_beta0 = np.concatenate((col_1s, input_X), axis=1)\n",
    "        \n",
    "        # algoritmo de gradiente descendente.\n",
    "        for iter in range(n_epochs):\n",
    "            # calcular gradiente\n",
    "            gradiente = gradient(X_train_con_beta0, input_Y ,self.beta)\n",
    "            # actualizar valores beta\n",
    "            self.beta = self.beta - (self.learning_rate * gradiente) \n",
    "\n",
    "    def query(self, input_X, prob=True, cutoff=0.5):\n",
    "        # Multiplicar cada muestra de test por los valores de los coeficientes obtenidos (beta)\n",
    "        mult_x_betas =  input_X*self.beta[1:self.beta.size]   \n",
    "        # Sumar los valores por fila (que cada observación de test) y sumarle el intercept (beta0)\n",
    "        y_val = mult_x_betas.sum(axis=1) + self.beta[0]\n",
    "\n",
    "        # A los resultados obtenidos, se le aplica la función sigmoid\n",
    "        y_pred_prob = sigmoid(y_val)\n",
    "        y_pred = np.array([])\n",
    "\n",
    "        if prob:\n",
    "            y_pred = y_pred_prob.reshape(-1,1)\n",
    "        else:    \n",
    "            # salida teniendo en cuenta el umbral la probabilidad obtenida y el umbral especificado\n",
    "            salida_pred_umbral = (y_pred_prob >= cutoff).astype(int)\n",
    "            y_pred = salida_pred_umbral.reshape(-1,1)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecutar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hiperparámetro para el regresor.\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y predecir.\n",
    "LR = LogisticRegression(learning_rate)\n",
    "LR.train(X_train, Y_train, 2000)\n",
    "Y_pred = LR.query(X_test,prob=False,cutoff=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.908\n"
     ]
    }
   ],
   "source": [
    "# Mostrar la exactitud\n",
    "acc = (Y_pred == Y_test.reshape(-1,1)).mean()\n",
    "print('Accuracy : {}'.format(np.round(acc,3)))\n",
    "sal_pred, rep_pred = np.unique(Y_pred, return_counts=True)\n",
    "#print('Datos de la predicción:' ,sal_pred, rep_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.92      0.93      0.93       144\n",
      "   malignant       0.88      0.87      0.87        84\n",
      "\n",
      "    accuracy                           0.91       228\n",
      "   macro avg       0.90      0.90      0.90       228\n",
      "weighted avg       0.91      0.91      0.91       228\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# y=0 -> Benign, y=1 -> maligno       \n",
    "# cambiar los nombres de las etiquetas de la salida\n",
    "list_etiq_invert = list(data['target_names'])\n",
    "list_etiq_invert.reverse()\n",
    "etiq_invert = np.array(list_etiq_invert)\n",
    "\n",
    "# Crea un informe de texto que muestra las principales métricas de clasificación.\n",
    "print(classification_report(Y_test, Y_pred, target_names=etiq_invert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy calculado con la librería metrics de sklearn: 0.9078947368421053\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Accuracy obtenido con la librería metrics de sklearn\n",
    "print( \"Accuracy calculado con la librería metrics de sklearn: \" + str(metrics.accuracy_score(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de predicciones erróneas:  21\n"
     ]
    }
   ],
   "source": [
    "num_pred_err = 0\n",
    "i = 0\n",
    "for pred in (Y_pred):\n",
    "    if pred != Y_test[i]:\n",
    "        num_pred_err += 1\n",
    "    i += 1    \n",
    "print('Número de predicciones erróneas: ', num_pred_err)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[134  10]\n",
      " [ 11  73]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "# Matriz de confusión\n",
    "# y=0 -> Benign, y=1 -> maligno\n",
    "matriz_conf = metrics.confusion_matrix(Y_test,Y_pred)\n",
    "print(\"Matriz de confusión: \")\n",
    "print(matriz_conf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
